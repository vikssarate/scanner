<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"/>
<meta name="apple-mobile-web-app-capable" content="yes"/>
<title>Scan & Merge — v2 (Auto Detect + OCR)</title>
<style>
:root{--bg:#0f1220;--ink:#eef1ff;--muted:#9aa3c7;--line:#2a3052;--accent:#6ca8ff;--ok:#7bd88f;--bad:#ff7575}
*{box-sizing:border-box} html,body{height:100%}
body{margin:0;background:#000;color:var(--ink);font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu}

/* ===== Camera fills screen ===== */
#camWrap{position:fixed; inset:0; background:#000}
#video{width:100%; height:100%; object-fit:cover; object-position:center; display:block}
#tapToShoot{
  position:absolute; inset:0; background:transparent !important; color:transparent;
  border:0; outline:none; -webkit-appearance:none; appearance:none; padding:0; cursor:pointer;
}
/* live guide overlay */
#guide{position:absolute; inset:0; pointer-events:none}

/* ===== Overlay UI (glass) ===== */
.ui{position:fixed; left:0; right:0; z-index:3; pointer-events:none}
.btn{
  appearance:none; border:1px solid rgba(255,255,255,.18);
  background:rgba(15,18,32,.35); color:var(--ink);
  padding:12px 16px; border-radius:12px; font-weight:600; cursor:pointer; backdrop-filter:saturate(180%) blur(8px);
  pointer-events:auto; font-size:15px;
}
.btn:disabled{opacity:.5; cursor:not-allowed}
.primary{background:rgba(108,168,255,.45); border-color:transparent; color:#07152a}
.ok{background:rgba(123,216,143,.45); border-color:transparent; color:#06210f}
.bad{background:rgba(255,117,117,.45); border-color:transparent; color:#2a0808}
.ghost{background:rgba(15,18,32,.2)}
.toggle.on{outline:2px solid rgba(125,211,252,.9)}

/* top bar */
.topbar{top:0; display:flex; align-items:center; justify-content:space-between;
  padding:calc(env(safe-area-inset-top,0) + 8px) 12px 8px}
.row{display:flex; gap:8px; flex-wrap:wrap}
.row.gap-lg{gap:16px}

/* right-side vertical tools (capture button etc.) */
.rightbar{position:fixed; right:12px; top:50%; transform:translateY(-50%); display:flex; gap:12px; flex-direction:column; z-index:3; pointer-events:none}
.round{width:72px; height:72px; border-radius:999px; display:inline-grid; place-items:center; font-weight:700}
.rightbar .btn{pointer-events:auto}

/* bottom drawer for thumbnails */
.drawer{position:fixed; left:0; right:0; bottom:0; padding:8px 8px calc(env(safe-area-inset-bottom,0) + 8px); z-index:3; pointer-events:none}
.panel{display:flex; gap:8px; align-items:center; justify-content:center; padding:8px; border-radius:14px;
  background:rgba(15,18,32,.35); border:1px solid rgba(255,255,255,.18); backdrop-filter:saturate(180%) blur(8px); pointer-events:auto; overflow:auto}
.thumb{position:relative; min-width:110px}
.thumb img{width:110px; height:82px; object-fit:cover; border-radius:10px; border:1px solid rgba(255,255,255,.18); background:#000}
.thumb button{position:absolute; top:6px; right:6px}

/* Crop stage */
#stage{position:fixed; inset:0; display:none; z-index:2}
#stage.ready{display:block}
#stage img{position:absolute; inset:0; margin:auto; max-width:min(100%, 100%); max-height:min(100%, 100%); border-radius:12px; display:block; user-select:none; -webkit-user-drag:none}
#cropBox{
  position:absolute; border:2px dashed rgba(255,255,255,.95); background:rgba(255,255,255,.05);
  box-shadow:0 0 0 100vmax rgba(0,0,0,.45); touch-action:none
}
.handle{position:absolute; width:18px; height:18px; border-radius:50%; background:#fff; border:2px solid #000}
.handle.nw{left:-10px; top:-10px} .handle.ne{right:-10px; top:-10px}
.handle.sw{left:-10px; bottom:-10px} .handle.se{right:-10px; bottom:-10px}

/* small text */
.small{font-size:12px; color:var(--muted)}
</style>
</head>
<body>

<!-- Fullscreen camera -->
<div id="camWrap">
  <video id="video" playsinline muted></video>
  <canvas id="guide"></canvas>
  <div id="tapToShoot" aria-label="Tap to capture"></div>
</div>

<!-- UI: top bar -->
<div class="ui topbar">
  <div class="row">
    <button id="startBtn" class="btn primary">Start</button>
    <button id="switchBtn" class="btn ghost" disabled>Switch</button>

    <button id="autoBtn" class="btn ghost toggle on" title="Auto detect & dewarp">Auto</button>
    <button id="enhanceBtn" class="btn ghost toggle" title="B/W enhance">Enhance</button>

    <button id="importBtn" class="btn ghost">Import</button>
    <input id="filePicker" type="file" accept="image/*" multiple style="display:none">
    <button id="clearBtn" class="btn bad" disabled>Clear</button>
  </div>

  <!-- Exports are in their own group so we can hide them while cropping -->
  <div id="exportsBar" class="row gap-lg">
    <button id="exportJPG" class="btn ghost" disabled>Export JPG</button>
    <button id="exportPDF" class="btn ghost" disabled>Export PDF</button>
    <button id="ocrAll" class="btn ghost" disabled>OCR (TXT)</button>
  </div>
</div>

<!-- UI: right side capture -->
<div class="rightbar">
  <button id="captureBtn" class="btn round primary" title="Capture">●</button>
</div>

<!-- Bottom drawer (thumbnails) -->
<div class="drawer">
  <div class="panel" id="galleryPanel">
    <span class="small" id="noPages">No pages yet</span>
    <div id="gallery" class="row"></div>
  </div>
</div>

<!-- Crop stage -->
<div id="stage">
  <img id="capturedImg" alt="Captured"/>
  <div id="cropBox">
    <div class="handle nw" data-dir="nw"></div>
    <div class="handle ne" data-dir="ne"></div>
    <div class="handle sw" data-dir="sw"></div>
    <div class="handle se" data-dir="se"></div>
  </div>
  <!-- crop actions in top-right -->
  <div class="ui topbar" style="justify-content:flex-end">
    <div class="row gap-lg">
      <button id="useCropBtn" class="btn ok">Use crop</button>
      <button id="retakeBtn" class="btn ghost">Retake</button>
    </div>
  </div>
</div>

<!-- libs: jsPDF, OpenCV.js, Tesseract.js -->
<script src="https://cdn.jsdelivr.net/npm/jspdf@2.5.1/dist/jspdf.umd.min.js"></script>
<script async src="https://docs.opencv.org/4.x/opencv.js"></script>
<script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>

<script>
(() => {
  const video = document.getElementById('video');
  const guide = document.getElementById('guide');
  const gctx = guide.getContext('2d');

  const tapToShoot = document.getElementById('tapToShoot');
  const startBtn = document.getElementById('startBtn');
  const switchBtn = document.getElementById('switchBtn');

  const autoBtn = document.getElementById('autoBtn');
  const enhanceBtn = document.getElementById('enhanceBtn');

  const importBtn = document.getElementById('importBtn');
  const filePicker = document.getElementById('filePicker');

  const captureBtn = document.getElementById('captureBtn');
  const clearBtn = document.getElementById('clearBtn');
  const exportJPG = document.getElementById('exportJPG');
  const exportPDF = document.getElementById('exportPDF');
  const ocrAllBtn = document.getElementById('ocrAll');
  const exportsBar = document.getElementById('exportsBar');

  const stage = document.getElementById('stage');
  const imgEl = document.getElementById('capturedImg');
  const cropBox = document.getElementById('cropBox');
  const useCropBtn = document.getElementById('useCropBtn');
  const retakeBtn = document.getElementById('retakeBtn');

  const gallery = document.getElementById('gallery');
  const noPages = document.getElementById('noPages');

  let stream = null;
  let usingRear = true;
  let pages = []; // {blob,url,w,h,text?}

  let importQueue = [];
  let cropSource = 'camera'; // 'camera' | 'import'
  let autoEnabled = true;
  let enhanceEnabled = false;

  // flags for libs
  let cvReady = false;
  let ocrReady = false;

  // OpenCV init
  const waitForCV = new Promise((res) => {
    const tick = () => {
      if (window.cv && cv.Mat) { cvReady = true; res(); }
      else setTimeout(tick, 80);
    };
    // When opencv.js finishes loading it sets onRuntimeInitialized
    if (window.cv) {
      cv['onRuntimeInitialized'] = () => { cvReady = true; res(); };
    }
    tick();
  });

  // OCR worker (lazy)
  let ocrWorker = null;
  async function ensureOCR() {
    if (ocrWorker) return;
    const { createWorker } = Tesseract;
    ocrWorker = await createWorker('eng'); // downloads eng traineddata
    ocrReady = true;
  }

  function uiCamera(on){
    switchBtn.disabled = !on;
    tapToShoot.classList.toggle('hint', on);
    resizeGuide();
    if (on && autoEnabled) startGuideLoop(); else stopGuideLoop();
  }
  function uiExports(){
    const on = pages.length > 0;
    exportJPG.disabled = !on;
    exportPDF.disabled = !on;
    clearBtn.disabled = !on;
    ocrAllBtn.disabled = !on;
    noPages.style.display = on ? 'none' : 'inline';
  }

  async function startCamera(rear=true){
    stopCamera();
    usingRear = rear;
    try{
      stream = await navigator.mediaDevices.getUserMedia({
        audio:false,
        video:{ facingMode: rear ? {ideal:'environment'} : 'user', width:{ideal:1920} }
      });
      video.srcObject = stream;
      await video.play();
      uiCamera(true);
    }catch(e){
      alert('Camera error: '+e.message+'\n(Use HTTPS and allow camera)');
      uiCamera(false);
    }
  }
  function stopCamera(){
    if (stream) stream.getTracks().forEach(t=>t.stop());
    stream = null; uiCamera(false);
  }

  function drawFrameToCanvas(scaleW=0){
    const vw = video.videoWidth || 1920, vh = video.videoHeight || 1080;
    const c = document.createElement('canvas');
    if (scaleW && vw) { c.width = scaleW; c.height = Math.round(scaleW * vh / vw); }
    else { c.width = vw; c.height = vh; }
    c.getContext('2d').drawImage(video, 0, 0, c.width, c.height); return c;
  }
  function canvasToBlob(canvas, type='image/jpeg', q=.95){
    return new Promise(res=>{
      if (canvas.toBlob) canvas.toBlob(b=>res(b), type, q);
      else { const d = canvas.toDataURL(type,q); res(dataURLToBlob(d)); }
    });
  }
  function dataURLToBlob(dataURL){
    const [h,d]=dataURL.split(','), mime=h.match(/:(.*?);/)[1];
    const b=atob(d), u=new Uint8Array(b.length); for(let i=0;i<b.length;i++) u[i]=b.charCodeAt(i);
    return new Blob([u],{type:mime});
  }
  function blobToDataURL(blob){ return new Promise(r=>{ const f=new FileReader(); f.onload=()=>r(f.result); f.readAsDataURL(blob); }); }

  // ==== Crop state ====
  let dragging=null, rect={x:0,y:0,w:100,h:100}, start=null, stageBox=null;

  function measureStage(){
    return new Promise(res=>requestAnimationFrame(()=>{
      stageBox = imgEl.getBoundingClientRect(); res();
    }));
  }
  function clamp(r){
    r.w = Math.max(24, Math.min(r.w, stageBox.width));
    r.h = Math.max(24, Math.min(r.h, stageBox.height));
    r.x = Math.max(0, Math.min(r.x, stageBox.width - r.w));
    r.y = Math.max(0, Math.min(r.y, stageBox.height - r.h));
  }
  function paintCrop(){
    cropBox.style.left = rect.x+'px'; cropBox.style.top = rect.y+'px';
    cropBox.style.width = rect.w+'px'; cropBox.style.height = rect.h+'px';
  }
  function showCropFromBlob(blob, source='camera'){
    cropSource = source;
    retakeBtn.textContent = (source === 'camera') ? 'Retake' : 'Cancel';
    const url = URL.createObjectURL(blob);
    imgEl.onload = async ()=>{
      stage.style.display='block'; await measureStage();
      rect.w = Math.round(stageBox.width*0.9); rect.h = Math.round(stageBox.height*0.9);
      rect.x = Math.round((stageBox.width-rect.w)/2); rect.y = Math.round((stageBox.height-rect.h)/2);
      paintCrop(); stage.classList.add('ready');
      if (exportsBar) exportsBar.style.display = 'none';
    };
    imgEl.src = url;
    imgEl.addEventListener('load', ()=>URL.revokeObjectURL(url), {once:true});
  }
  function hideCrop(){
    stage.classList.remove('ready'); stage.style.display='none';
    if (exportsBar) exportsBar.style.display = 'flex';
  }
  function cssRectToImageRect(){
    const sx = imgEl.naturalWidth / stageBox.width;
    const sy = imgEl.naturalHeight / stageBox.height;
    return { sx:Math.round(rect.x*sx), sy:Math.round(rect.y*sy), sw:Math.round(rect.w*sx), sh:Math.round(rect.h*sy) };
  }

  cropBox.addEventListener('pointerdown', e=>{
    const dir = e.target.dataset.dir; dragging = dir || 'move';
    start = {x:e.clientX, y:e.clientY, rect:{...rect}}; cropBox.setPointerCapture(e.pointerId);
  }, {passive:false});
  cropBox.addEventListener('pointermove', e=>{
    if(!dragging) return;
    const dx=e.clientX-start.x, dy=e.clientY-start.y; let r={...start.rect};
    if (dragging==='move'){ r.x+=dx; r.y+=dy; }
    else { if(dragging.includes('w')){ r.x+=dx; r.w-=dx; }
           if(dragging.includes('e')) r.w+=dx;
           if(dragging.includes('n')){ r.y+=dy; r.h-=dy; }
           if(dragging.includes('s')) r.h+=dy; }
    clamp(r); rect=r; paintCrop();
  }, {passive:false});
  cropBox.addEventListener('pointerup', ()=>dragging=null);
  cropBox.addEventListener('lostpointercapture', ()=>dragging=null);

  // ==== Gallery ====
  function renderGallery(){
    gallery.innerHTML='';
    pages.forEach((p,i)=>{
      const d=document.createElement('div'); d.className='thumb';
      const im=document.createElement('img'); im.src=p.url; im.alt=`Page ${i+1}`;
      const del=document.createElement('button'); del.className='btn bad small'; del.textContent='×';
      del.onclick=()=>{ URL.revokeObjectURL(p.url); pages.splice(i,1); renderGallery(); uiExports(); };
      d.append(im,del); gallery.appendChild(d);
    });
    uiExports();
  }

  // ==== Controls ====
  startBtn.onclick = () => startCamera(true);
  switchBtn.onclick = () => startCamera(!usingRear);

  autoBtn.onclick = ()=>{
    autoEnabled = !autoEnabled;
    autoBtn.classList.toggle('on', autoEnabled);
    if (stream) { if (autoEnabled) startGuideLoop(); else stopGuideLoop(true); }
  };
  enhanceBtn.onclick = ()=>{
    enhanceEnabled = !enhanceEnabled;
    enhanceBtn.classList.toggle('on', enhanceEnabled);
  };

  const doCapture = async ()=>{
    if (!stream || stage.classList.contains('ready')) return;
    const canvas = drawFrameToCanvas();
    let blob = await canvasToBlob(canvas, 'image/jpeg', 0.92);
    blob = await pipelineAuto(blob); // auto detect + warp + enhance if enabled
    showCropFromBlob(blob, 'camera');
  };
  tapToShoot.onclick = doCapture;
  captureBtn.onclick = doCapture;

  // Import flow
  importBtn.onclick = () => { if (!stage.classList.contains('ready')) filePicker.click(); };
  filePicker.onchange = (e)=>{
    const files = Array.from(e.target.files || []).filter(f => f.type.startsWith('image/'));
    if (!files.length) return;
    importQueue.push(...files);
    if (!stage.classList.contains('ready')) processNextImport();
    filePicker.value = '';
  };

  async function processNextImport(){
    if (!importQueue.length) return;
    const next = importQueue.shift();
    let blob = next instanceof Blob ? next : new Blob([next], {type: next.type || 'image/jpeg'});
    blob = await pipelineAuto(blob);
    showCropFromBlob(blob, 'import');
  }

  // Crop actions
  retakeBtn.onclick = () => {
    hideCrop();
    if (cropSource === 'import') processNextImport();
  };

  useCropBtn.onclick = async ()=>{
    const {sx,sy,sw,sh} = cssRectToImageRect();
    const c=document.createElement('canvas'); c.width=sw; c.height=sh;
    c.getContext('2d').drawImage(imgEl, sx, sy, sw, sh, 0, 0, sw, sh);
    const blob = await canvasToBlob(c, 'image/jpeg', .95);
    const url = URL.createObjectURL(blob);
    pages.push({blob,url,w:sw,h:sh});
    hideCrop(); renderGallery();
    if (cropSource === 'import' && importQueue.length) processNextImport();
  };

  clearBtn.onclick = ()=>{
    if(!pages.length) return;
    if(confirm('Remove all pages?')){ pages.forEach(p=>URL.revokeObjectURL(p.url)); pages=[]; renderGallery(); }
  };

  // ==== Export (image-only) ====
  exportJPG.onclick = async ()=>{
    if(!pages.length) return;
    const useBitmap = 'createImageBitmap' in window;
    const imgs = await ( useBitmap
      ? Promise.all(pages.map(p=>createImageBitmap(p.blob, {imageOrientation:'from-image'}).catch(()=>createImageBitmap(p.blob))))
      : Promise.all(pages.map(p=>new Promise(r=>{const i=new Image(); i.onload=()=>r(i); i.src=p.url;}))) );

    const targetW = Math.max(...imgs.map(im=>im.width)), pad=8;
    const totalH = imgs.reduce((s,im)=>s+Math.round(im.height*(targetW/im.width)),0) + pad*(imgs.length-1);
    const c=document.createElement('canvas'); c.width=targetW; c.height=totalH;
    const ctx=c.getContext('2d'); let y=0;
    imgs.forEach(im=>{ const h=Math.round(im.height*(targetW/im.width)); ctx.drawImage(im,0,y,targetW,h); y+=h+pad; });
    c.toBlob(b=>downloadBlob(b,'scan-merged.jpg'),'image/jpeg',.95);
  };

  exportPDF.onclick = async ()=>{
    if(!pages.length) return;
    const { jsPDF } = window.jspdf; const doc=new jsPDF({unit:'mm',format:'a4'});
    for(let i=0;i<pages.length;i++){
      if(i>0) doc.addPage();
      const dataURL = await blobToDataURL(pages[i].blob);
      await addImageFitA4(doc, dataURL);
    }
    doc.save('scan.pdf');
  };

  // ==== OCR (TXT) ====
  ocrAllBtn.onclick = async ()=>{
    if (!pages.length) return;
    ocrAllBtn.disabled = true; ocrAllBtn.textContent = 'OCR…';
    try{
      await ensureOCR();
      let all = '';
      for (let i=0;i<pages.length;i++){
        const { data } = await ocrWorker.recognize(pages[i].blob);
        const text = (data && data.text) ? data.text.trim() : '';
        pages[i].text = text;
        all += `\n\n===== Page ${i+1} =====\n` + text;
      }
      const txtBlob = new Blob([all.trim()], {type:'text/plain'});
      downloadBlob(txtBlob, 'scan-ocr.txt');
    } catch(e){
      alert('OCR failed: '+ e.message);
    } finally {
      ocrAllBtn.textContent = 'OCR (TXT)'; ocrAllBtn.disabled = false;
    }
  };

  async function addImageFitA4(doc, dataUrl){
    const im = await new Promise(r=>{ const i=new Image(); i.onload=()=>r(i); i.src=dataUrl; });
    const pageW=doc.internal.pageSize.getWidth(), pageH=doc.internal.pageSize.getHeight();
    let w=pageW, h=(im.height*w)/im.width; if(h>pageH){ h=pageH; w=(im.width*h)/im.height; }
    const x=(pageW-w)/2, y=(pageH-h)/2; doc.addImage(dataUrl,'JPEG',x,y,w,h);
  }
  function downloadBlob(blob, name){
    const url=URL.createObjectURL(blob); const a=document.createElement('a'); a.href=url; a.download=name;
    document.body.appendChild(a); a.click(); a.remove(); setTimeout(()=>URL.revokeObjectURL(url),1000);
  }

  // ====== Auto Detect + Dewarp Pipeline (OpenCV.js) ======
  async function pipelineAuto(inBlob){
    if (!autoEnabled){ return inBlob; }
    try{
      await waitForCV;
      const bitmap = await createImageBitmap(inBlob, {imageOrientation:'from-image'});
      // draw to small canvas for detection
      const maxW = 1600;
      const sC = document.createElement('canvas');
      const scale = bitmap.width > maxW ? maxW / bitmap.width : 1;
      sC.width = Math.round(bitmap.width * scale);
      sC.height = Math.round(bitmap.height * scale);
      const sCx = sC.getContext('2d');
      sCx.drawImage(bitmap, 0, 0, sC.width, sC.height);
      const imgData = sCx.getImageData(0,0,sC.width,sC.height);

      let src = cv.matFromImageData(imgData);            // RGBA
      let gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      let blur = new cv.Mat();
      cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);

      let edges = new cv.Mat();
      cv.Canny(blur, edges, 60, 160);
      // thicken edges a bit
      let kernel = cv.Mat.ones(3,3, cv.CV_8U);
      cv.dilate(edges, edges, kernel);

      // find largest 4-point contour
      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      let best = null, bestArea = 0;
      for (let i=0; i<contours.size(); i++){
        const cnt = contours.get(i);
        const peri = cv.arcLength(cnt, true);
        const approx = new cv.Mat();
        cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
        if (approx.rows === 4){
          const area = cv.contourArea(approx);
          if (area > bestArea){
            bestArea = area;
            best = approx; // keep this approx (Mat)
          } else approx.delete();
        } else approx.delete();
        cnt.delete();
      }

      let warpedBlob = inBlob; // fallback
      if (best && bestArea > 5000){
        // order points: tl,tr,br,bl
        const pts = [];
        for (let r=0;r<4;r++){
          const p = { x: best.data32S[r*2], y: best.data32S[r*2+1] };
          pts.push(p);
        }
        const ordered = orderCorners(pts);

        // map to A4-ish rectangle based on width
        const w = Math.hypot(ordered.tr.x - ordered.tl.x, ordered.tr.y - ordered.tl.y);
        const h = Math.hypot(ordered.bl.x - ordered.tl.x, ordered.bl.y - ordered.tl.y);
        const targetW = Math.max(1000, Math.round(Math.max(w,h))); // keep good detail
        const targetH = Math.round(targetW * 1.4142); // A4 ratio

        const srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
          ordered.tl.x, ordered.tl.y,
          ordered.tr.x, ordered.tr.y,
          ordered.br.x, ordered.br.y,
          ordered.bl.x, ordered.bl.y
        ]);
        const dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
          0, 0,
          targetW-1, 0,
          targetW-1, targetH-1,
          0, targetH-1
        ]);

        const M = cv.getPerspectiveTransform(srcTri, dstTri);
        let warped = new cv.Mat();
        cv.warpPerspective(gray, warped, M, new cv.Size(targetW, targetH), cv.INTER_LINEAR, cv.BORDER_REPLICATE);

        // optional enhance: adaptive threshold (B/W)
        let outMat = new cv.Mat();
        if (enhanceEnabled){
          cv.adaptiveThreshold(warped, outMat, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 31, 10);
        } else {
          outMat = warped.clone();
        }

        // encode to JPEG
        const outCanvas = document.createElement('canvas');
        outCanvas.width = outMat.cols; outCanvas.height = outMat.rows;
        const octx = outCanvas.getContext('2d');
        // putImageData needs RGBA
        const rgba = new cv.Mat();
        cv.cvtColor(outMat, rgba, cv.COLOR_GRAY2RGBA);
        const imgDataOut = new ImageData(new Uint8ClampedArray(rgba.data), rgba.cols, rgba.rows);
        octx.putImageData(imgDataOut, 0, 0);
        warpedBlob = await canvasToBlob(outCanvas, 'image/jpeg', .95);

        // cleanup
        rgba.delete(); outMat.delete(); warped.delete(); M.delete(); srcTri.delete(); dstTri.delete();
      }

      // cleanup base mats
      kernel.delete(); edges.delete(); contours.delete(); hierarchy.delete(); blur.delete(); gray.delete(); src.delete();
      if (best) best.delete();

      return warpedBlob;
    } catch(e){
      console.warn('Auto pipeline error', e);
      return inBlob;
    }
  }

  function orderCorners(pts){
    // sum & diff trick
    const sum = pts.map(p=>p.x+p.y);
    const diff = pts.map(p=>p.x-p.y);
    const tl = pts[sum.indexOf(Math.min(...sum))];
    const br = pts[sum.indexOf(Math.max(...sum))];
    const tr = pts[diff.indexOf(Math.max(...diff))];
    const bl = pts[diff.indexOf(Math.min(...diff))];
    return {tl,tr,br,bl};
  }

  // ====== Live Guide Loop (edge + quad) ======
  let guideRAF = null, guideTmpCanvas = document.createElement('canvas');
  function resizeGuide(){
    const r = document.getElementById('camWrap').getBoundingClientRect();
    guide.width = r.width; guide.height = r.height;
  }
  function startGuideLoop(){
    if (!cvReady) return;
    if (guideRAF) cancelAnimationFrame(guideRAF);
    const draw = ()=>{
      if (!stream || !autoEnabled){ guideRAF = null; gctx.clearRect(0,0,guide.width,guide.height); return; }
      const vw = video.videoWidth, vh = video.videoHeight;
      if (!vw || !vh){ guideRAF = requestAnimationFrame(draw); return; }

      // sample smaller
      const sW = 480, sH = Math.round(sW * vh / vw);
      guideTmpCanvas.width = sW; guideTmpCanvas.height = sH;
      guideTmpCanvas.getContext('2d').drawImage(video, 0, 0, sW, sH);
      const id = guideTmpCanvas.getContext('2d').getImageData(0,0,sW,sH);
      try{
        let src = cv.matFromImageData(id);
        let gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        let blur = new cv.Mat(); cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);
        let edges = new cv.Mat(); cv.Canny(blur, edges, 60, 160);
        let kernel = cv.Mat.ones(3,3, cv.CV_8U); cv.dilate(edges, edges, kernel);
        let contours = new cv.MatVector(); let hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let best=null, area=0;
        for(let i=0;i<contours.size();i++){
          const cnt=contours.get(i); const peri=cv.arcLength(cnt,true);
          const approx=new cv.Mat(); cv.approxPolyDP(cnt,approx,0.02*peri,true);
          if (approx.rows===4){
            const a=cv.contourArea(approx);
            if(a>area){ if(best) best.delete(); best=approx; area=a; } else approx.delete();
          } else approx.delete();
          cnt.delete();
        }

        gctx.clearRect(0,0,guide.width,guide.height);
        if (best && area>1500){
          const pts=[]; for(let r=0;r<4;r++){ pts.push({x:best.data32S[r*2], y:best.data32S[r*2+1]}); }
          const ord = orderCorners(pts);
          // scale from sample to canvas size
          const scaleX = guide.width / sW, scaleY = guide.height / sH;
          gctx.lineWidth = 3;
          gctx.strokeStyle = 'rgba(123,216,143,0.9)';
          gctx.beginPath();
          gctx.moveTo(ord.tl.x*scaleX, ord.tl.y*scaleY);
          gctx.lineTo(ord.tr.x*scaleX, ord.tr.y*scaleY);
          gctx.lineTo(ord.br.x*scaleX, ord.br.y*scaleY);
          gctx.lineTo(ord.bl.x*scaleX, ord.bl.y*scaleY);
          gctx.closePath(); gctx.stroke();
        }

        // clean
        if (best) best.delete();
        kernel.delete(); contours.delete(); hierarchy.delete(); edges.delete(); blur.delete(); gray.delete(); src.delete();
      }catch(e){
        // ignore per-frame errors
      }
      guideRAF = requestAnimationFrame(draw);
    };
    draw();
  }
  function stopGuideLoop(clear=false){
    if (guideRAF) cancelAnimationFrame(guideRAF);
    guideRAF = null;
    if (clear) gctx.clearRect(0,0,guide.width,guide.height);
  }

  // Save battery when hidden
  document.addEventListener('visibilitychange', ()=>{ if(document.hidden) { stopCamera(); stopGuideLoop(true); } });

  // init
  uiCamera(false); uiExports();
})();
</script>
</body>
</html>
